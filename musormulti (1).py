# -*- coding: utf-8 -*-
"""musormulti.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ymjGOmozGcl03t4yWs76_Kib22VcS2m3
"""

import os
import sys
import random
import math
import re
import time
import numpy as np
import cv2
import matplotlib
import matplotlib.pyplot as plt
import json
import pandas as pd
import cv2

from skimage.io import imread, imshow, imread_collection, concatenate_images
from skimage.transform import resize

class_names = ['accumulator', 'brake']

!pip install tensorflow-gpu==1.15.0
!pip install keras==2.2.5

import os #
from google.colab import drive #модуль для работы с google диском

drive.mount('/content/drive/') # монтируем google диск

!git clone https://github.com/matterport/Mask_RCNN.git

# Commented out IPython magic to ensure Python compatibility.
# %cd Mask_RCNN/
!python setup.py install

!git clone https://github.com/Shamil2017/priborPanelDataset

!pip install 'h5py==2.10.0' --force-reinstall

# example of inference with a pre-trained coco model
from keras.preprocessing.image import load_img
from keras.preprocessing.image import img_to_array
from mrcnn.config import Config
from mrcnn.model import MaskRCNN
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt
import tensorflow as tf
import numpy as np
# example of extracting bounding boxes from an annotation file
from xml.etree import ElementTree
import os
from mrcnn.utils import Dataset
from mrcnn.config import Config
from mrcnn.model import MaskRCNN
from mrcnn.visualize import display_instances
import re

class FoodConfig(Config):
    """Configuration for training on the toy  dataset.
    Derives from the base Config class and overrides some values.
    """
    # Give the configuration a recognizable name
    NAME = "food"

    # We use a GPU with 12GB memory, which can fit two images.
    # Adjust down if you use a smaller GPU.
    IMAGES_PER_GPU = 2

    # Number of classes (including background)
    NUM_CLASSES = 1 + 2  # Background + balloon

    # Number of training steps per epoch
    STEPS_PER_EPOCH = 100

    # Skip detections with < 90% confidence
    DETECTION_MIN_CONFIDENCE = 0.9

# class that defines and loads the kangaroo dataset
class MusorDataset(Dataset):
  # extract bounding boxes from an annotation file
  def extract_boxes(self,filename):
        # load and parse the file
        tree = ElementTree.parse(filename)
        # get the root of the document
        root = tree.getroot()
        # extract each bounding box
        boxes = list()
        for box in root.findall('.//bndbox'):
            xmin = int(box.find('xmin').text)
            ymin = int(box.find('ymin').text)
            xmax = int(box.find('xmax').text)
            ymax = int(box.find('ymax').text)
            coors = [xmin, ymin, xmax, ymax]
            boxes.append(coors)
        # extract image dimensions
        width = int(root.find('.//size/width').text)
        height = int(root.find('.//size/height').text)
        folder = str(root.find('.//folder').text)
        return boxes, width, height, folder
  # load the dataset definitions      
  def load_dataset(self, dataset_dir, is_train=True):
        # define  classes
        self.add_class("dataset", 1, "accumulator")
        self.add_class("dataset", 2, "brake")
        #self.add_class("dataset", 1, "diesel")
        #self.add_class("dataset", 1, "engine")
        #self.add_class("dataset", 1, "Engine Overheating")
        #self.add_class("dataset", 1, "oil")

        # define data locations
        images_dir = dataset_dir + '/Images/'
        
        annotations_dir = dataset_dir + '/Annots/'
        # find all images
        # find all images     
        for filename in os.listdir(images_dir):
           if filename.find("accum") != -1:
              # extract image id
              image_id = filename[11:-5]       
              # skip all images after 20 if we are building the train set
              if is_train and int(image_id) >= 38:
                  continue
              # skip all images before 20 if we are building the test/val set
              if not is_train and int(image_id) < 38:
                  continue
              
              img_path = images_dir + filename
              ann_path = annotations_dir + 'accumulator'+image_id + '.xml'
              boxes, w, h, folder = self.extract_boxes(ann_path)    
              if (folder=='Accumulator'):
                  classId=[1]
              if (folder=='Brake'):
                  classId=[2]
              # add to dataset
              self.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path, class_ids=classId)

  # load the dataset definitions      
  def load_mask(self, image_id):
        # get details of image
        info = self.image_info[image_id]
        # define box file location
        path = info['annotation']
        # load XML
        boxes, w, h, folder = self.extract_boxes(path)
        # create one array for all masks, each on a different channel
        masks = np.zeros([h, w, len(boxes)], dtype='uint8')
        # create masks
        class_ids = list()

        for i in range(len(boxes)):
            box = boxes[i]
            row_s, row_e = box[1], box[3]
            col_s, col_e = box[0], box[2]
            if (folder=='Accumulator'):
               masks[row_s:row_e, col_s:col_e, i] = 1
               class_ids.append(1)
            if (folder=='Brake'):
               masks[row_s:row_e, col_s:col_e, i] = 1
               class_ids.append(2)
        return masks, np.asarray(class_ids, dtype='int32')           
        
   
  # load an image reference      
  def image_reference(self, image_id):
        info = self.image_info[image_id]
        return info['path']

# train set
train_set = MusorDataset()
train_set.load_dataset('priborPanelDataset', is_train=True)
train_set.prepare()
print('Train: %d' % len(train_set.image_ids))
# test/val set
test_set = MusorDataset()
test_set.load_dataset('priborPanelDataset', is_train=False)
test_set.prepare()
print('Test: %d' % len(test_set.image_ids))

# load an image
image_id = 35
image = train_set.load_image(image_id)
print(image.shape)
# load image mask
mask, class_ids = train_set.load_mask(image_id)

# plot image
#plt.imshow(image)
# plot mask
plt.imshow(mask[:, :, 0], cmap='gray', alpha=0.5)
plt.show()

mask.shape

!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5

# define a configuration for the model
class MusorConfig(Config):
    # Give the configuration a recognizable name
    NAME = "Musor_cfg"
    # Number of classes (background + kangaroo)
    NUM_CLASSES = 1 + 2
    # Number of training steps per epoch
    STEPS_PER_EPOCH = 131
# prepare config
config = MusorConfig()

# define the model
model = MaskRCNN(mode='training', model_dir='./', config=config)

# load weights (mscoco)
model.load_weights("mask_rcnn_coco.h5", by_name=True, exclude=['mrcnn_class_logits','mrcnn_bbox_fc', 'mrcnn_bbox', 'mrcnn_mask'])

# train weights (output layers or 'heads')
model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=5,
layers='heads')

# define the prediction configuration
class PredictionConfig(Config):
    # define the name of the configuration
    NAME = "Musor_cfg"
    # number of classes (background + kangaroo)
    NUM_CLASSES = 1 + 2
    # simplify GPU config
    GPU_COUNT = 1
    IMAGES_PER_GPU = 1

# create config
cfg = PredictionConfig()
# define the model
model = MaskRCNN(mode='inference', model_dir='./', config=cfg)

model_path = "mask_rcnn_musor_cfg_0005.h5"
model.load_weights(model_path, by_name=True)

# calculate the mAP for a model on a given dataset
def evaluate_model(dataset, model, cfg):
    APs = list()
    for image_id in dataset.image_ids:
      # load image, bounding boxes and masks for the image id
      image, _, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id,
      use_mini_mask=False)
      # convert pixel values (e.g. center)
      scaled_image = mold_image(image, cfg)
      # convert image into one sample
      sample = expand_dims(scaled_image, 0)
      # make prediction
      yhat = model.detect(sample, verbose=0)
      # extract results for first sample
      r = yhat[0]
      # calculate statistics, including AP
      AP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r["rois"], r["class_ids"],
      r["scores"], r["masks"])
      # store
      APs.append(AP)
    # calculate the mean AP across all images
    mAP = mean(APs)
    return mAP

# load the train dataset
train_set = MusorDataset()
train_set.load_dataset('priborPanelDataset', is_train=True)
train_set.prepare()
print('Train: %d' % len(train_set.image_ids))
# load the test dataset
test_set = MusorDataset()
test_set.load_dataset('priborPanelDataset', is_train=False)
test_set.prepare()
print('Test: %d' % len(test_set.image_ids))
# create config
cfg = PredictionConfig()
# define the model
model = MaskRCNN(mode='inference', model_dir='./', config=cfg)
# load model weights
model.load_weights('mask_rcnn_musor_cfg_0005.h5', by_name=True)
# evaluate model on training dataset
train_mAP = evaluate_model(train_set, model, cfg)

# load and prepare the image
def load_image(filename):
  # load the image
  img = load_img(filename, target_size=(128, 128))
  # convert to array
  img = img_to_array(img)
  # reshape into a single sample with 3 channels
  img = img.reshape(1, 128, 128, 3)
  # center pixel data
  img = img.astype('float32')
  img = img - [123.68, 116.779, 103.939]
  return img

from mrcnn.model import mold_image
from numpy import zeros
from numpy import asarray
from numpy import expand_dims
from mrcnn import visualize

# load image
image = load_img(os.path.join('priborPanelDataset/Images', 'accumulator5.jpeg') )
image = img_to_array(image)
# convert pixel values (e.g. center)
scaled_image = mold_image(image, cfg)
# convert image into one sample
sample = expand_dims(scaled_image, 0)
# make prediction
yhat = model.detect(sample, verbose=0)
r = yhat[0]
print(r['class_ids'])
display_instances(image, r['rois'], r['masks'], r['class_ids']-1, class_names, r['scores'])

for i in range(1,56):
  b = "% s" % i

  filename = 'accumulator'+b+'.jpeg'
  print(filename)
  image = load_img(os.path.join('priborPanelDataset/Images', filename) )
  
  image = img_to_array(image)
  # convert pixel values (e.g. center)
  scaled_image = mold_image(image, cfg)
  # convert image into one sample
  sample = expand_dims(scaled_image, 0)
  # make prediction
  yhat = model.detect(sample, verbose=0)
  r = yhat[0]
  r['rois']
  display_instances(image, r['rois'], r['masks'], r['class_ids']-1, class_names, r['scores'])